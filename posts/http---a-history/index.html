<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Http - A History - Lewis Metcalf</title><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Http - A History"><meta property="og:description" content="A few notes based on this great video HTTP/1 TCP/IP The first and most simple approach, making a TCP handshake for each resource which has to be shared.
The downsides to this approach is that in order to speed up transfer rates, we want to send many resource pieces in parallel. With HTTP/1, this means doing a new TCP handshake every-time, which is costly and time consuming. This was alleviated in a later version HTTP/1."><meta property="og:type" content="article"><meta property="og:url" content="https://leweym.github.io/posts/http---a-history/"><meta property="article:section" content="posts"><meta name=twitter:card content="summary"><meta name=twitter:title content="Http - A History"><meta name=twitter:description content="A few notes based on this great video HTTP/1 TCP/IP The first and most simple approach, making a TCP handshake for each resource which has to be shared.
The downsides to this approach is that in order to speed up transfer rates, we want to send many resource pieces in parallel. With HTTP/1, this means doing a new TCP handshake every-time, which is costly and time consuming. This was alleviated in a later version HTTP/1."><link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel=stylesheet><link href=/css/fontawesome-all.min.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://leweym.github.io/css/notice.css><link rel=stylesheet type=text/css media=screen href=https://leweym.github.io/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://leweym.github.io/css/main.css><link rel=stylesheet type=text/css media=screen href=https://leweym.github.io/css/bootstrap.css><script src=https://leweym.github.io/js/main.js></script>
<script type=application/javascript>function resizeIFrameToFitContent(e){e.width=e.contentWindow.document.body.scrollWidth,e.height=e.contentWindow.document.body.scrollHeight}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6FPTHJ5QN"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Q6FPTHJ5QN")</script></head><body><div class="container wrapper post"><div class=header><h1 class=site-title><a href=https://leweym.github.io/>Lewis Metcalf</a></h1><div class=site-description><nav class="nav social"><ul class=flat></ul></nav></div><nav class=nav><ul class=flat></ul></nav></div><br><div class=post-header><h1 class=title>Http - A History</h1><div class=meta></div></div><aside><nav id=TableOfContents><ul><li><a href=#http1>HTTP/1</a></li><li><a href=#http2>HTTP/2</a></li><li><a href=#http3>HTTP/3</a></li></ul></nav></aside><div class=markdown><p>A few notes based on this <a href="https://www.youtube.com/watch?v=ai8cf0hZ9cQ&t=536s">great video</a></p><h2 id=http1>HTTP/1</h2><h3 id=tcpip>TCP/IP</h3><p>The first and most simple approach, making a TCP handshake for each resource which has to be shared.</p><p>The downsides to this approach is that in order to speed up transfer rates, we want to send many resource pieces in parallel. With HTTP/1, this means doing a new TCP handshake every-time, which is costly and time consuming. This was alleviated in a later version HTTP/1.1 which enabled the <code>keep-alive</code> option so that multiple calls could share the same connection handshake.</p><p>However, multiple calls still had to be serialised one by one, and the only way to make concurrent calls was with multiple TCP connections. Even though the cost of the handshake is saved, concurrency is still not achieved.</p><h2 id=http2>HTTP/2</h2><h3 id=tcpip-multiplexing>TCP/IP, multiplexing</h3><p>HTTP/2 introduced multiplexing of streams of data over a single tcp connection. This meant true concurrency at the network level as the client could request multiple tcp connections in parallel.</p><p>However, this also brought a downside when it comes to packet loss. This is because the HTTP/2 protocol is not aware of <em>where</em> in the stream of data the data is lost; only that <em>some</em> data was lost. The only solution available is to resend all of the tcp connections data streams, this is known as <code>head of line blocking</code>.</p><h2 id=http3>HTTP/3</h2><h3 id=quicip-fast-handshake-udp-connections>QUIC/IP, fast handshake, UDP connections</h3><p>HTTP/3 streams packets concurrently over UDP connections. This is an unsigned and so unreliable protocol, but the client is able to resend packets with data loss without effecting the other concurrent connections.</p><p>Also, because of the UDP connections, the handshake protocol has been greatly reduced to carry out all necessary passing of keys, encryption, etc, in a single back-and-forth, greatly reducing round trip time over HTTP/2 which needed to carry out 2 or more back-and-forths.</p></div><div class=post-tags></div></div><div class="footer wrapper"><nav class=nav><div><a href=https://github.com/vividvilla/ezhil>Ezhil theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></nav></div></body></html>